import cloudscraper
from bs4 import BeautifulSoup
import csv
import os

def the_beast_auto_scanner():
    # Ø§Ù„Ù…ØµØ¯Ø±: Ù‚Ø³Ù… Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª Ø§Ù„ØªØ±ÙƒÙŠØ© (ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù„Ù‚Ø³Ù…)
    base_url = "https://k.3sk.media/turkish-series/" 
    scraper = cloudscraper.create_scraper()
    
    try:
        print("ğŸ” Ø¬Ø§Ø±ÙŠ ØªÙ…Ø´ÙŠØ· Ø§Ù„Ù‚Ø³Ù… Ø§Ù„ØªØ±ÙƒÙŠ...")
        response = scraper.get(base_url)
        soup = BeautifulSoup(response.content, 'html.parser')

        # 1. Ø§Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø­Ù„Ù‚Ø§Øª ÙÙŠ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ù‚Ø³Ù…
        # Ù…Ù„Ø§Ø­Ø¸Ø©: Ù†Ø¹Ø¯Ù„ Ø§Ù„ÙˆØ³Ù… Ø­Ø³Ø¨ ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹ (ØºØ§Ù„Ø¨Ø§Ù‹ Ù…Ø§ ÙŠÙƒÙˆÙ† h2 Ø£Ùˆ a Ø¯Ø§Ø®Ù„ div Ù…Ø­Ø¯Ø¯)
        episodes = soup.find_all('article') or soup.find_all('div', class_='item')

        file_name = 'database.csv'
        
        # ÙØªØ­ Ø§Ù„Ù…Ù„Ù Ù„Ù„Ù…Ø³Ø­ ÙˆØ§Ù„ÙƒØªØ§Ø¨Ø© Ù…Ù† Ø¬Ø¯ÙŠØ¯ Ù„ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø§Ø¨Ø· Raw Ù…Ø­Ø¯Ø« Ø¯Ø§Ø¦Ù…Ø§Ù‹
        with open(file_name, mode='w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(['name', 'url']) # Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†

            for ep in episodes[:10]: # Ø³Ø­Ø¨ Ø¢Ø®Ø± 10 Ø­Ù„Ù‚Ø§Øª Ù†Ø²Ù„ÙˆØ§
                link_tag = ep.find('a', href=True)
                if not link_tag: continue
                
                ep_url = link_tag['href']
                ep_name = link_tag.text.strip() or "Ø­Ù„Ù‚Ø© Ø¬Ø¯ÙŠØ¯Ø©"

                # 2. Ø§Ù„Ø¢Ù† Ù†Ø¯Ø®Ù„ Ù„Ù€ "Ù‚Ù„Ø¨" ÙƒÙ„ Ø­Ù„Ù‚Ø© Ù„Ø³Ø­Ø¨ Ø§Ù„Ø±Ø§Ø¨Ø·
                print(f"ğŸ“¡ ÙØ­Øµ Ø­Ù„Ù‚Ø©: {ep_name}")
                inner_res = scraper.get(ep_url)
                inner_soup = BeautifulSoup(inner_res.content, 'html.parser')
                
                watch_link = ""
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Iframe Ø§Ù„Ù…Ø´ØºÙ„
                iframe = inner_soup.find('iframe', src=True)
                if iframe:
                    watch_link = iframe['src']
                    if watch_link.startswith('//'):
                        watch_link = 'https:' + watch_link
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ù„Ù Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø±Ø§Ø¨Ø·
                if watch_link:
                    writer.writerow([ep_name, watch_link])
                    print(f"âœ… ØªÙ… Ø³Ø­Ø¨ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù€: {ep_name}")

        print("âœ¨ Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ«! Ù…Ù„Ù database.csv Ø¬Ø§Ù‡Ø².")

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ: {e}")

if __name__ == "__main__":
    the_beast_auto_scanner()
