import requests
import csv
import re
import cloudscraper
import os

SOURCES = [
    "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/ar.m3u",
    "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/s.m3u"
]
SPORTS_KEYWORDS = ['sport', 'beIN', 'SSC', 'KSA', 'Ø±ÙŠØ§Ø¶Ø©']
DB_FILE = 'database.csv'

def check_link(url):
    """ÙØ­Øµ Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ø±Ø§Ø¨Ø·: Ù‡Ù„ ÙŠØ±Ø³Ù„ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠØ¯ÙŠÙˆØŸ"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        with requests.get(url, timeout=5, stream=True, headers=headers) as r:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙƒÙˆØ¯ 200 ÙŠØ¹Ù†ÙŠ Ø§Ù„Ø±Ø§Ø¨Ø· Ø­ÙŠ
            return r.status_code == 200
    except:
        return False

def is_token_link(url):
    token_patterns = ['token=', 'key=', 'auth', 'pass', 'user']
    if any(p in url.lower() for p in token_patterns): return True
    return any(len(segment) > 25 for segment in url.split('/'))

def start_process():
    scraper = cloudscraper.create_scraper()
    final_list = []
    seen_urls = set()

    # 1. ÙØ­Øµ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙˆØ­Ø°Ù Ø§Ù„ØªØ§Ù„Ù Ù…Ù†Ù‡Ø§
    if os.path.exists(DB_FILE):
        print("ğŸ” ÙØ­Øµ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„...")
        with open(DB_FILE, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                url = row['url']
                if check_link(url): # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠØ¹Ù…Ù„
                    final_list.append(row)
                    seen_urls.add(url)
                else:
                    print(f"ğŸ—‘ï¸ Ø­Ø°Ù Ø±Ø§Ø¨Ø· ØªØ§Ù„Ù: {row['title']}")

    # 2. Ø¬Ù„Ø¨ Ù‚Ù†ÙˆØ§Øª Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ¥Ø¶Ø§ÙØªÙ‡Ø§
    print("ğŸ“¡ Ø¬Ù„Ø¨ Ù‚Ù†ÙˆØ§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±...")
    for source in SOURCES:
        try:
            response = scraper.get(source, timeout=15)
            matches = re.findall(r'#EXTINF:.*?,(.*?)\n(http.*?)\n', response.text)
            for name, url in matches:
                url = url.strip()
                if any(key in name.lower() for key in SPORTS_KEYWORDS):
                    if not is_token_link(url) and url not in seen_urls:
                        if check_link(url):
                            final_list.append({'title': name.strip(), 'url': url})
                            seen_urls.add(url)
                            print(f"âœ… Ø¥Ø¶Ø§ÙØ© Ù‚Ù†Ø§Ø© Ø¬Ø¯ÙŠØ¯Ø©: {name}")
        except: continue

    # 3. Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ (Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø´ØºØ§Ù„Ø© ÙÙ‚Ø·)
    with open(DB_FILE, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=['title', 'url'])
        writer.writeheader()
        writer.writerows(final_list)
    
    print(f"âœ¨ ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ«! Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„ÙŠ: {len(final_list)} Ù‚Ù†Ø§Ø© Ø´ØºØ§Ù„Ø©.")

if __name__ == "__main__":
    start_process()
